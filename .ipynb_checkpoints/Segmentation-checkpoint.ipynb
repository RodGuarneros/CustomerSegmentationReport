{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a1fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# magic visualizations\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdd04e",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Create a customer segmentation report based on census information and e-mail sales by a company, using demographic information to determine how customers are different to general population. Then use this analysis to make predictions to figure out wich members of the general population are more lekely to become a customer for the e-mail order company, <b>based on a unsupervised machine learning model</b>.\n",
    "\n",
    "Based on this report, the company would be able to define a marketing strategy so as to reach more consumer out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a7bbd06",
   "metadata": {},
   "source": [
    "# 1. Metadata \n",
    "\n",
    "Lets talk about the data files available for this project:\n",
    "\n",
    "- Udacity_AZDIAS_052018.csv: Demographics data for the general population of Germany; 891 211 persons (rows) x 366 features (columns).\n",
    "- Udacity_CUSTOMERS_052018.csv: Demographics data for customers of a mail order company; 191 652 persons (rows) x 369 features (columns).\n",
    "- Udacity_MAILOUT_052018_TRAIN.csv: Demographics data for individuals who were targets of a marketing campaign; 42 982 persons (rows) x 367 (columns).\n",
    "- Udacity_MAILOUT_052018_TEST.csv: Demographics data for individuals who were targets of a marketing campaign; 42 833 persons (rows) x 366 (columns).\n",
    "\n",
    "Each row of the demographics files represents a single person, but also includes information outside of individuals, including information about their household, building, and neighborhood. Use the information from the first two files to figure out how customers (\"CUSTOMERS\") are similar or different from the general population at large (\"AZDIAS\"), then use your analysis to make predictions on the other two files (\"MAILOUT\"), predicting which recipients are most likely to become a customer for the mail-order company.\n",
    "\n",
    "The \"CUSTOMERS\" file contains three extra columns ('CUSTOMER_GROUP', 'ONLINE_PURCHASE', and 'PRODUCT_GROUP'), which provide broad information about the customers depicted in the file. The original \"MAILOUT\" file included one additional column, <b>\"RESPONSE\"</b>, which indicated whether or not each recipient became a customer of the company. For the \"TRAIN\" subset, this column has been retained, but in the \"TEST\" subset it has been removed; it is against that withheld column that your final predictions will be assessed in the Kaggle competition.\n",
    "\n",
    "Otherwise, all of the remaining columns are the same between the three data files. For more information about the columns depicted in the files, you can refer to two Excel spreadsheets provided in the workspace. One of them is a top-level list of attribuxtes and descriptions, organized by informational category. The other is a detailed mapping of data values for each feature in alphabetical order.\n",
    "\n",
    "The DIAS information level includes the sort of mindful by every row:\n",
    "\n",
    "- social minded\n",
    "- familiar minded\n",
    "- religious\n",
    "- material minded\n",
    "- dreamily\n",
    "- sensual minded\n",
    "- eventful orientated\n",
    "- cultural minded\n",
    "- rational mind\n",
    "- critical minded\n",
    "- dominant minded\n",
    "- fightfull attitude\n",
    "- traditional minded\n",
    "- traditional minded\n",
    "\n",
    "In the below cell, we've provided some initial code to load in the first two datasets. Note for all of the .csv data files in this project that they're semicolon (;) delimited, so an additional argument in the read_csv() call has been included to read in the data properly. Also, considering the size of the datasets, it may take some time for them to load completely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792179d5",
   "metadata": {},
   "source": [
    "# The approach used to know datasets can be split in the following steps:\n",
    "## 1. Extract, Transform and Load\n",
    "<b>Extract</b>: Gathering the information from every dataset.\n",
    "\n",
    "<b>Transform</b>: Data cleaning, summarization, selection, joining, filtering and aggregating.\n",
    "\n",
    "<b>Load</b>: Relational or not relational database, locally or in AWS.\n",
    "\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Unsupervised Machine Learning Model: Clustering analysis\n",
    "4. Customer segmentation report\n",
    "5. Supervised Machine Learning Model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9981c2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c595c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
